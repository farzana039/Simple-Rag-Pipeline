# Simple RAG Pipeline

This project is a beginner-friendly tutorial for building a **Retrieval Augmented Generation (RAG) system**.  
It showcases the end-to-end process of document indexing, retrieval, AI-powered response generation, and evaluation â€” all through a simple **command-line interface (CLI).**

## ğŸ”¹ What is RAG?
RAG (Retrieval Augmented Generation) is a framework that combines information retrieval with large language models (LLMs). It retrieves relevant content from a knowledge base and augments the modelâ€™s response with accurate, contextual information.

## ğŸš€ Features
- **Document Indexing** â€“ Process and split documents (e.g., PDFs, text files) into smaller, manageable chunks.  
- **Vector Storage & Retrieval** â€“ Store document embeddings in a **vector database (LanceDB)** and perform similarity search to retrieve relevant content.  
- **AI-Powered Response Generation** â€“ Use the **OpenAI API** to generate concise answers grounded in the retrieved context.  
- **Response Evaluation** â€“ Compare generated answers against expected outputs and analyze reasoning behind evaluations.  

## ğŸ› ï¸ Tech Stack
- **Python** â€“ Core language  
- **LanceDB** â€“ Vector database for embeddings  
- **OpenAI API** â€“ For LLM-powered response generation  
- **LangChain** â€“ Orchestration of RAG pipeline  
- **Typer** â€“ CLI framework  

## ğŸ¯ Purpose
This project is designed as a **learning resource** for anyone new to Retrieval Augmented Generation.  
By exploring this repo, you will understand how to:  
1. Ingest and process documents.  
2. Create embeddings and store them in a vector DB.  
3. Query documents and augment responses with context.  
4. Evaluate and benchmark the results.  

---

